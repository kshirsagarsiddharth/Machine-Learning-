{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../input/clean-16-million-tweets/clean_tweets_again.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.drop(columns = 'Unnamed: 0',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is split in 98|1|1\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_validation_test,y_train,y_validation_test = train_test_split(X,y,test_size = 0.02,random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation,X_test,y_validation,y_test = train_test_split(X_validation_test,y_validation_test,test_size = 0.5,random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams with stopwords\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=8,\n",
      "                   warm_start=False)\n",
      "\n",
      "\n",
      "validation result for 10000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   41.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  41.9s\n",
      "the training and testing time is 145.1356291770935 seconds\n",
      "accuracy 0.8125430737422468 greater than null accuracy 0.5044170164776643\n",
      "validation result for 20000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   45.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  45.9s\n",
      "the training and testing time is 151.2620289325714 seconds\n",
      "accuracy 0.8155504041100182 greater than null accuracy 0.5044170164776643\n",
      "validation result for 30000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   50.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  50.5s\n",
      "the training and testing time is 156.54662346839905 seconds\n",
      "accuracy 0.8193095670697325 greater than null accuracy 0.5044170164776643\n",
      "validation result for 40000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   51.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  51.7s\n",
      "the training and testing time is 157.61210918426514 seconds\n",
      "accuracy 0.8221915920055134 greater than null accuracy 0.5044170164776643\n",
      "validation result for 50000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   55.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  55.6s\n",
      "the training and testing time is 161.4466860294342 seconds\n",
      "accuracy 0.8216277175615563 greater than null accuracy 0.5044170164776643\n",
      "validation result for 60000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   59.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.0min\n",
      "the training and testing time is 165.6408669948578 seconds\n",
      "accuracy 0.8226301610174801 greater than null accuracy 0.5044170164776643\n",
      "validation result for 70000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.1min\n",
      "the training and testing time is 172.86976146697998 seconds\n",
      "accuracy 0.8224422028694944 greater than null accuracy 0.5044170164776643\n",
      "validation result for 80000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.1min\n",
      "the training and testing time is 173.91493606567383 seconds\n",
      "accuracy 0.8231940354614372 greater than null accuracy 0.5044170164776643\n",
      "validation result for 90000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.2min\n",
      "the training and testing time is 180.78782296180725 seconds\n",
      "accuracy 0.8237579099053944 greater than null accuracy 0.5044170164776643\n",
      "validation result for 100000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.2min\n",
      "the training and testing time is 180.48186445236206 seconds\n",
      "accuracy 0.8246350479293277 greater than null accuracy 0.5044170164776643\n"
     ]
    }
   ],
   "source": [
    "print('bigrams with stopwords')\n",
    "if len(X_test[y_test == 0])/len(X_test) > 0.5:\n",
    "    null_accuracy = len(X_test[y_test == 0]) / len(X_test)\n",
    "else:\n",
    "    null_accuracy = 1 - len(X_test[y_test == 0]) / len(X_test)\n",
    "number_of_features = np.arange(10000,100001,10000)\n",
    "clf = LogisticRegression(n_jobs = -1,verbose = 8)\n",
    "count_vec = TfidfVectorizer()\n",
    "result_bigrams_with_stopwords = []\n",
    "print(clf)\n",
    "print('\\n')\n",
    "for number in number_of_features:\n",
    "    count_vec.set_params(stop_words = None,max_features = number,ngram_range = (1,2))\n",
    "    pipeline = Pipeline([('vectorizer',count_vec),('classifier',clf)],verbose = 1)\n",
    "    print('validation result for {} features'.format(number))\n",
    "    t0 = time()\n",
    "    pipeline.fit(X_train,y_train)\n",
    "    pred = pipeline.predict(X_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(pred,y_test)\n",
    "    print('the training and testing time is',train_test_time,'seconds')\n",
    "    if accuracy > null_accuracy:\n",
    "        print('accuracy',accuracy,'greater than null accuracy',null_accuracy)\n",
    "    else:\n",
    "        print('accuracy',accuracy,'less than null accuracy',null_accuracy)\n",
    "    result_bigrams_with_stopwords.append((number,accuracy,train_test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams without stopwords\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=8,\n",
      "                   warm_start=False)\n",
      "\n",
      "\n",
      "validation result for 10000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   32.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  33.0s\n",
      "the training and testing time is 123.39035844802856 seconds\n",
      "accuracy 0.7750767495770942 greater than null accuracy 0.5044170164776643\n",
      "validation result for 20000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   36.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  36.8s\n",
      "the training and testing time is 125.67383098602295 seconds\n",
      "accuracy 0.7793371342647704 greater than null accuracy 0.5044170164776643\n",
      "validation result for 30000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   38.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  38.7s\n",
      "the training and testing time is 128.09212446212769 seconds\n",
      "accuracy 0.7814046738926133 greater than null accuracy 0.5044170164776643\n",
      "validation result for 40000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   42.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  42.4s\n",
      "the training and testing time is 133.43876385688782 seconds\n",
      "accuracy 0.7834095608044609 greater than null accuracy 0.5044170164776643\n",
      "validation result for 50000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   46.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  46.4s\n",
      "the training and testing time is 136.1623888015747 seconds\n",
      "accuracy 0.7840987406804085 greater than null accuracy 0.5044170164776643\n",
      "validation result for 60000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   50.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  50.2s\n",
      "the training and testing time is 141.16444611549377 seconds\n",
      "accuracy 0.7847252678403609 greater than null accuracy 0.5044170164776643\n",
      "validation result for 70000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   52.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  52.7s\n",
      "the training and testing time is 142.4143557548523 seconds\n",
      "accuracy 0.7864795438882276 greater than null accuracy 0.5044170164776643\n",
      "validation result for 80000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   54.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  54.6s\n",
      "the training and testing time is 144.19275760650635 seconds\n",
      "accuracy 0.7862289330242466 greater than null accuracy 0.5044170164776643\n",
      "validation result for 90000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   58.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  58.9s\n",
      "the training and testing time is 148.32224416732788 seconds\n",
      "accuracy 0.7866675020362133 greater than null accuracy 0.5044170164776643\n",
      "validation result for 100000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.0min\n",
      "the training and testing time is 151.94053077697754 seconds\n",
      "accuracy 0.7873566819121609 greater than null accuracy 0.5044170164776643\n"
     ]
    }
   ],
   "source": [
    "print('bigrams without stopwords')\n",
    "if len(X_test[y_test == 0]) / len(X_test) > 0.5:\n",
    "    null_accuracy = len(X_test[y_test == 0]) / len(X_test)\n",
    "else:\n",
    "    null_accuracy = 1 - len(X_test[y_test == 0]) / len(X_test)\n",
    "number_of_features = np.arange(10000,100001,10000)\n",
    "clf = LogisticRegression(n_jobs = -1,verbose = 8)\n",
    "count_vec = TfidfVectorizer()\n",
    "result_bigrams_without_stopwords = []\n",
    "print(clf)\n",
    "print('\\n')\n",
    "for number in number_of_features:\n",
    "    count_vec.set_params(stop_words = 'english',max_features = number,ngram_range = (1,2))\n",
    "    pipeline = Pipeline([('vectorizer',count_vec),('classifier',clf)],verbose = 1)\n",
    "    print('validation result for {} features'.format(number))\n",
    "    t0 = time()\n",
    "    pipeline.fit(X_train,y_train)\n",
    "    pred = pipeline.predict(X_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(pred,y_test)\n",
    "    print('the training and testing time is',train_test_time,'seconds')\n",
    "    if accuracy > null_accuracy:\n",
    "        print('accuracy',accuracy,'greater than null accuracy',null_accuracy)\n",
    "    else:\n",
    "        print('accuracy',accuracy,'less than null accuracy',null_accuracy)\n",
    "    result_bigrams_without_stopwords.append((number,accuracy,train_test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bigrams_with_stopwords_df = pd.DataFrame(result_bigrams_with_stopwords,columns = ['features','score','time in sec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bigrams_with_stopwords_df.to_csv('result_bigrams_with_stopwords_df.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bigrams_without_stopwords_df = pd.DataFrame(result_bigrams_without_stopwords,columns = ['features','score','time in sec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bigrams_without_stopwords_df.to_csv('result_bigrams_without_stopwords_df.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "      <th>time in sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.775077</td>\n",
       "      <td>123.390358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.779337</td>\n",
       "      <td>125.673831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.781405</td>\n",
       "      <td>128.092124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40000</td>\n",
       "      <td>0.783410</td>\n",
       "      <td>133.438764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.784099</td>\n",
       "      <td>136.162389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60000</td>\n",
       "      <td>0.784725</td>\n",
       "      <td>141.164446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70000</td>\n",
       "      <td>0.786480</td>\n",
       "      <td>142.414356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80000</td>\n",
       "      <td>0.786229</td>\n",
       "      <td>144.192758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90000</td>\n",
       "      <td>0.786668</td>\n",
       "      <td>148.322244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.787357</td>\n",
       "      <td>151.940531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features     score  time in sec\n",
       "0     10000  0.775077   123.390358\n",
       "1     20000  0.779337   125.673831\n",
       "2     30000  0.781405   128.092124\n",
       "3     40000  0.783410   133.438764\n",
       "4     50000  0.784099   136.162389\n",
       "5     60000  0.784725   141.164446\n",
       "6     70000  0.786480   142.414356\n",
       "7     80000  0.786229   144.192758\n",
       "8     90000  0.786668   148.322244\n",
       "9    100000  0.787357   151.940531"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_bigrams_without_stopwords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "      <th>time in sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.812543</td>\n",
       "      <td>145.135629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.815550</td>\n",
       "      <td>151.262029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.819310</td>\n",
       "      <td>156.546623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40000</td>\n",
       "      <td>0.822192</td>\n",
       "      <td>157.612109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.821628</td>\n",
       "      <td>161.446686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60000</td>\n",
       "      <td>0.822630</td>\n",
       "      <td>165.640867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70000</td>\n",
       "      <td>0.822442</td>\n",
       "      <td>172.869761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80000</td>\n",
       "      <td>0.823194</td>\n",
       "      <td>173.914936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90000</td>\n",
       "      <td>0.823758</td>\n",
       "      <td>180.787823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.824635</td>\n",
       "      <td>180.481864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features     score  time in sec\n",
       "0     10000  0.812543   145.135629\n",
       "1     20000  0.815550   151.262029\n",
       "2     30000  0.819310   156.546623\n",
       "3     40000  0.822192   157.612109\n",
       "4     50000  0.821628   161.446686\n",
       "5     60000  0.822630   165.640867\n",
       "6     70000  0.822442   172.869761\n",
       "7     80000  0.823194   173.914936\n",
       "8     90000  0.823758   180.787823\n",
       "9    100000  0.824635   180.481864"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_bigrams_with_stopwords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
