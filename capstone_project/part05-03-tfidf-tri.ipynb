{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../input/clean-16-million-tweets/clean_tweets_again.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.drop(columns = 'Unnamed: 0',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is split in 98|1|1\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_validation_test,y_train,y_validation_test = train_test_split(X,y,test_size = 0.02,random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation,X_test,y_validation,y_test = train_test_split(X_validation_test,y_validation_test,test_size = 0.5,random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation with trigram with stopwords\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=8,\n",
      "                   warm_start=False)\n",
      "\n",
      "\n",
      "validation result for 10000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   43.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  43.4s\n",
      "the training and testing time is  297.2369122505188  seconds\n",
      "accuracy 0.8112273667063468 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 20000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   47.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  47.4s\n",
      "the training and testing time is  314.5771219730377  seconds\n",
      "accuracy 0.8139840862101372 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 30000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   51.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  51.2s\n",
      "the training and testing time is  317.72068071365356  seconds\n",
      "accuracy 0.8185577344777896 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 40000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   56.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  56.5s\n",
      "the training and testing time is  323.2113118171692  seconds\n",
      "accuracy 0.8198734415136896 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 50000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   59.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  60.0s\n",
      "the training and testing time is  326.7244074344635  seconds\n",
      "accuracy 0.8238205626213896 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 60000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.1min\n",
      "the training and testing time is  328.35508489608765  seconds\n",
      "accuracy 0.8230687300294468 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 70000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.2min\n",
      "the training and testing time is  334.97183060646057  seconds\n",
      "accuracy 0.824697700645323 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 80000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.2min\n",
      "the training and testing time is  341.5641293525696  seconds\n",
      "accuracy 0.8259507549652277 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 90000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.3min\n",
      "the training and testing time is  350.96977972984314  seconds\n",
      "accuracy 0.8250736169412944 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 100000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.3min\n",
      "the training and testing time is  352.38519525527954  seconds\n",
      "accuracy 0.8258881022492325 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('computation with trigram with stopwords')\n",
    "if len(X_test[y_test == 0])/len(X_test) > 0.5:\n",
    "    null_accuracy = len(X_test[y_test == 0])/len(X_test)\n",
    "else:\n",
    "    null_accuracy = 1 - len(x_test[y_test == 0])/len(X_test)\n",
    "number_of_features = np.arange(10000,100001,10000)\n",
    "clf = LogisticRegression(n_jobs = -1,verbose = 8)\n",
    "count_vec = TfidfVectorizer()\n",
    "result_trigram_without_stopwords = []\n",
    "print(clf)\n",
    "print('\\n')\n",
    "for number in number_of_features:\n",
    "    count_vec.set_params(stop_words = None,max_features = number,ngram_range = (1,3))\n",
    "    pipeline = Pipeline([('vectorizer',count_vec),('classifier',clf)],verbose = 1)\n",
    "    print('validation result for {} features'.format(number))\n",
    "    t0 = time()\n",
    "    pipeline.fit(X_train,y_train)\n",
    "    pred = pipeline.predict(X_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(pred,y_test)\n",
    "    print('the training and testing time is ',train_test_time,' seconds')\n",
    "    if accuracy > null_accuracy:\n",
    "        print('accuracy',accuracy,'greater then null accuracy',null_accuracy)\n",
    "    else:\n",
    "        print('accuracy',accuracy,'less than null accuracy',null_accuracy)\n",
    "    print('\\n')  \n",
    "    result_trigram_without_stopwords.append((number,accuracy,train_test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation with tri without stopwords\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=8,\n",
      "                   warm_start=False)\n",
      "\n",
      "\n",
      "validation result for 10000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   34.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  34.4s\n",
      "the training and testing time is  213.27794194221497  seconds\n",
      "accuracy 0.7752020550090847 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 20000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   37.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  37.5s\n",
      "the training and testing time is  217.58858275413513  seconds\n",
      "accuracy 0.7794624396967609 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 30000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   41.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  41.8s\n",
      "the training and testing time is  225.74906086921692  seconds\n",
      "accuracy 0.7825324227805275 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 40000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   45.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  45.3s\n",
      "the training and testing time is  227.4021873474121  seconds\n",
      "accuracy 0.7823444646325418 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 50000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   47.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  47.6s\n",
      "the training and testing time is  229.34357047080994  seconds\n",
      "accuracy 0.7837854771004323 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 60000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   49.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  49.8s\n",
      "the training and testing time is  232.01800417900085  seconds\n",
      "accuracy 0.7845373096923751 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 70000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   53.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  53.3s\n",
      "the training and testing time is  235.291565656662  seconds\n",
      "accuracy 0.7853517950003133 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 80000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   57.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  57.8s\n",
      "the training and testing time is  242.82011938095093  seconds\n",
      "accuracy 0.7859156694442704 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 90000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   60.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.0min\n",
      "the training and testing time is  244.65954899787903  seconds\n",
      "accuracy 0.7861036275922562 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n",
      "validation result for 100000 features\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.1min\n",
      "the training and testing time is  247.5771996974945  seconds\n",
      "accuracy 0.7859783221602656 greater then null accuracy 0.5044170164776643\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('computation with tri without stopwords')\n",
    "if len(X_test[y_test == 0])/len(X_test) > 0.5:\n",
    "    null_accuracy = len(X_test[y_test == 0])/len(X_test)\n",
    "else:\n",
    "    null_accuracy = 1 - len(x_test[y_test == 0])/len(X_test)\n",
    "number_of_features = np.arange(10000,100001,10000)\n",
    "clf = LogisticRegression(n_jobs = -1,verbose = 8)\n",
    "count_vec = TfidfVectorizer()\n",
    "result_trigram_without_stopwords = []\n",
    "print(clf)\n",
    "print('\\n')\n",
    "for number in number_of_features:\n",
    "    count_vec.set_params(stop_words = 'english',max_features = number,ngram_range = (1,3))\n",
    "    pipeline = Pipeline([('vectorizer',count_vec),('classifier',clf)],verbose = 1)\n",
    "    print('validation result for {} features'.format(number))\n",
    "    t0 = time()\n",
    "    pipeline.fit(X_train,y_train)\n",
    "    pred = pipeline.predict(X_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(pred,y_test)\n",
    "    print('the training and testing time is ',train_test_time,' seconds')\n",
    "    if accuracy > null_accuracy:\n",
    "        print('accuracy',accuracy,'greater then null accuracy',null_accuracy)\n",
    "    else:\n",
    "        print('accuracy',accuracy,'less than null accuracy',null_accuracy)\n",
    "    print('\\n')  \n",
    "    result_trigram_without_stopwords.append((number,accuracy,train_test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_trigram_with_stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1964cd401eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_trigram_with_stopwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df3.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_trigram_without_stopwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df4.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result_trigram_with_stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(result_trigram_with_stopwords)\n",
    "df1.to_csv('df3.csv',encoding='utf-8')\n",
    "\n",
    "df1 = pd.DataFrame(result_trigram_without_stopwords)\n",
    "df1.to_csv('df4.csv',encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
